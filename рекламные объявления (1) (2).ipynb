{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9175edb3-811b-4af9-aa06-dd736b9d4837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ЗАПУСК ЭКСПЕРИМЕНТА ===\n",
      "ЗАГРУЗКА ОБУЧАЮЩИХ ДАННЫХ...\n",
      "\n",
      "============================================================\n",
      "АНАЛИЗ КОДИРОВКИ: ads.csv\n",
      "============================================================\n",
      "1. Chardet:          ascii (уверенность: 100.00%)\n",
      "Ошибка в методе 2 (charset-normalizer): 'CharsetMatch' object has no attribute 'confidence'\n",
      "2. Charset-Normalizer: Не определена (уверенность: 0.00%)\n",
      "3. Перебор кодировок:  utf-8 (уверенность: 100.00%)\n",
      "\n",
      "РЕКОМЕНДУЕМАЯ КОДИРОВКА: ascii\n",
      "(определено методом: Chardet, уверенность: 100.00%)\n",
      "✓ Файл успешно загружен с кодировкой: ascii\n",
      "\n",
      "ЗАГРУЗКА ТЕСТОВЫХ ДАННЫХ...\n",
      "\n",
      "============================================================\n",
      "АНАЛИЗ КОДИРОВКИ: test.tsv.csv\n",
      "============================================================\n",
      "1. Chardet:          ascii (уверенность: 100.00%)\n",
      "Ошибка в методе 2 (charset-normalizer): 'CharsetMatch' object has no attribute 'confidence'\n",
      "2. Charset-Normalizer: Не определена (уверенность: 0.00%)\n",
      "3. Перебор кодировок:  utf-8 (уверенность: 100.00%)\n",
      "\n",
      "РЕКОМЕНДУЕМАЯ КОДИРОВКА: ascii\n",
      "(определено методом: Chardet, уверенность: 100.00%)\n",
      "✓ Файл успешно загружен с кодировкой: ascii\n",
      "Данные загружены: Train (564, 4), Val (242, 4)\n",
      "\n",
      "=== ОБУЧЕНИЕ МОДЕЛЕЙ ===\n",
      "\n",
      "=== БЕЙЗЛАЙН МОДЕЛЬ ===\n",
      "Baseline Accuracy: 0.535 ± 0.022\n",
      "\n",
      "=== ОБУЧЕНИЕ LOGISTICREGRESSION ===\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Best params: {'model__solver': 'liblinear', 'model__penalty': 'l2', 'model__class_weight': None, 'model__C': 0.1}\n",
      "Accuracy: 0.551 ± 0.009\n",
      "\n",
      "=== ОБУЧЕНИЕ RANDOMFOREST ===\n",
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    }
   ],
   "source": [
    "# Необходимые импорты\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "from datetime import datetime\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score\n",
    "from sklearn.model_selection import (RandomizedSearchCV, cross_val_score, \n",
    "                                   StratifiedKFold, KFold)\n",
    "from sklearn.compose import make_column_selector, ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, RobustScaler, PolynomialFeatures\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from scipy import stats\n",
    "import joblib\n",
    "import warnings\n",
    "import os\n",
    "import chardet\n",
    "from charset_normalizer import from_bytes\n",
    "\n",
    "# Настройки\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "pd.set_option('display.max_columns', None)\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)\n",
    "\n",
    "\n",
    "# 1. Безопасная загрузка данных\n",
    "def safe_load_data():\n",
    "    try:\n",
    "        train_path = \"ads.csv\"\n",
    "        test_path = \"test.tsv.csv\"\n",
    "        \n",
    "        if not os.path.exists(train_path):\n",
    "            raise FileNotFoundError(f\"Файл {train_path} не найден\")\n",
    "        \n",
    "        print(\"ЗАГРУЗКА ОБУЧАЮЩИХ ДАННЫХ...\")\n",
    "        train = load_with_best_encoding(train_path)\n",
    "            \n",
    "        if 'successful' not in train.columns:\n",
    "            raise ValueError(\"В данных отсутствует целевая переменная 'successful'\")\n",
    "            \n",
    "        if os.path.exists(test_path):\n",
    "            print(\"\\nЗАГРУЗКА ТЕСТОВЫХ ДАННЫХ...\")\n",
    "            test = load_with_best_encoding(test_path)\n",
    "        else:\n",
    "            print(\"Тестовые данные не найдены, будет использована пустая DataFrame\")\n",
    "            test = pd.DataFrame()\n",
    "            \n",
    "        return train, test\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при загрузке данных: {str(e)}\")\n",
    "        return pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "# 2. Предобработка данных\n",
    "def preprocess_data(train, test):\n",
    "    try:\n",
    "        train = train.drop_duplicates().dropna(how='all')\n",
    "        if not test.empty:\n",
    "            test = test.drop_duplicates().dropna(how='all')\n",
    "        \n",
    "        for df in [train, test]:\n",
    "            if not df.empty:\n",
    "                for col in df.select_dtypes(include='object').columns:\n",
    "                    try:\n",
    "                        df[col] = pd.to_numeric(df[col].astype(str).str.replace(',','.'), errors='raise')\n",
    "                    except:\n",
    "                        try:\n",
    "                            df[col] = pd.to_numeric(df[col].astype(str).str.replace(',',''), errors='raise')\n",
    "                        except:\n",
    "                            continue\n",
    "        \n",
    "        return train.drop(columns=['successful']), train['successful'], test\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при предобработке данных: {str(e)}\")\n",
    "        return pd.DataFrame(), pd.Series(), pd.DataFrame()\n",
    "\n",
    "# 3. Анализ данных\n",
    "def analyze_data(X, y):\n",
    "    print(\"\\n=== АНАЛИЗ ДАННЫХ ===\")\n",
    "    print(f\"Размер обучающей выборки: {X.shape}\")\n",
    "    print(\"\\nРаспределение классов:\")\n",
    "    print(y.value_counts(normalize=True))\n",
    "    \n",
    "    numeric_cols = X.select_dtypes(include=np.number).columns\n",
    "    if len(numeric_cols) > 0:\n",
    "        corr_matrix = pd.concat([X[numeric_cols], y], axis=1).corr()\n",
    "        print(\"\\nКорреляции с целевой переменной:\")\n",
    "        print(corr_matrix['successful'].sort_values(ascending=False))\n",
    "        \n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "        plt.title(\"Матрица корреляций\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"\\nНет числовых признаков для анализа корреляций\")\n",
    "\n",
    "# 4. Создание упрощенного пайплайна\n",
    "def create_preprocessor():\n",
    "    numeric_transformer = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', RobustScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "    ])\n",
    "\n",
    "    return ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, make_column_selector(dtype_include=np.number)),\n",
    "            ('cat', categorical_transformer, make_column_selector(dtype_include=object))\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "\n",
    "# 5. Настройка моделей\n",
    "def get_models():\n",
    "    return {\n",
    "        'LogisticRegression': {\n",
    "            'model': LogisticRegression(max_iter=1000, random_state=SEED),\n",
    "            'params': {\n",
    "                'model__C': [0.1, 1.0, 10.0],\n",
    "                'model__penalty': ['l2'],\n",
    "                'model__solver': ['liblinear'],\n",
    "                'model__class_weight': [None, 'balanced']\n",
    "            }\n",
    "        },\n",
    "        'RandomForest': {\n",
    "            'model': RandomForestClassifier(random_state=SEED),\n",
    "            'params': {\n",
    "                'model__n_estimators': [100, 200],\n",
    "                'model__max_depth': [None, 10],\n",
    "                'model__min_samples_split': [2, 5]\n",
    "            }\n",
    "        },\n",
    "        'XGBoost': {\n",
    "            'model': XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=SEED),\n",
    "            'params': {\n",
    "                'model__n_estimators': [100, 200],\n",
    "                'model__max_depth': [3, 5],\n",
    "                'model__learning_rate': [0.01, 0.1]\n",
    "            }\n",
    "        },\n",
    "        'LightGBM': {\n",
    "            'model': LGBMClassifier(random_state=SEED, verbose=-1),\n",
    "            'params': {\n",
    "                'model__num_leaves': [31, 63],\n",
    "                'model__learning_rate': [0.05, 0.1],\n",
    "                'model__n_estimators': [100, 200]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "# 6. Обучение и оценка моделей\n",
    "def train_and_evaluate(X, y, preprocessor, models):\n",
    "    results = []\n",
    "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=SEED)\n",
    "    \n",
    "    # Бейзлайн модель\n",
    "    baseline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', LogisticRegression(max_iter=1000, random_state=SEED))\n",
    "    ])\n",
    "    \n",
    "    print(\"\\n=== БЕЙЗЛАЙН МОДЕЛЬ ===\")\n",
    "    try:\n",
    "        baseline_scores = cross_val_score(baseline, X, y, cv=cv, scoring='accuracy', n_jobs=1)\n",
    "        baseline_accuracy = np.mean(baseline_scores)\n",
    "        print(f\"Baseline Accuracy: {baseline_accuracy:.3f} ± {np.std(baseline_scores):.3f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при обучении бейзлайн модели: {str(e)}\")\n",
    "        baseline_scores = np.array([0.5, 0.5, 0.5])\n",
    "        baseline_accuracy = 0.5\n",
    "\n",
    "    # Обучение всех моделей\n",
    "    for model_name, config in models.items():\n",
    "        try:\n",
    "            print(f\"\\n=== ОБУЧЕНИЕ {model_name.upper()} ===\")\n",
    "            \n",
    "            pipeline = Pipeline([\n",
    "                ('preprocessor', preprocessor),\n",
    "                ('model', config['model'])\n",
    "            ])\n",
    "            \n",
    "            search = RandomizedSearchCV(\n",
    "                estimator=pipeline,\n",
    "                param_distributions=config['params'],\n",
    "                n_iter=5,\n",
    "                cv=cv,\n",
    "                scoring='accuracy',\n",
    "                refit=True,\n",
    "                n_jobs=1,\n",
    "                random_state=SEED,\n",
    "                verbose=1\n",
    "            )\n",
    "            \n",
    "            search.fit(X, y)\n",
    "            \n",
    "            cv_scores = cross_val_score(search.best_estimator_, X, y, cv=cv, scoring='accuracy', n_jobs=1)\n",
    "            mean_accuracy = np.mean(cv_scores)\n",
    "            std_accuracy = np.std(cv_scores)\n",
    "            \n",
    "            results.append({\n",
    "                'model': model_name,\n",
    "                'best_params': search.best_params_,\n",
    "                'mean_accuracy': mean_accuracy,\n",
    "                'std_accuracy': std_accuracy,\n",
    "                'best_estimator': search.best_estimator_\n",
    "            })\n",
    "            \n",
    "            print(f\"Best params: {search.best_params_}\")\n",
    "            print(f\"Accuracy: {mean_accuracy:.3f} ± {std_accuracy:.3f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Ошибка при обучении {model_name}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    if results:\n",
    "        results_df = pd.DataFrame(results)\n",
    "        results_df = results_df.sort_values('mean_accuracy', ascending=False)\n",
    "        results_df.to_csv('models_evaluation.csv', index=False)\n",
    "        \n",
    "        print(\"\\n=== РЕЗУЛЬТАТЫ МОДЕЛЕЙ ===\")\n",
    "        print(results_df[['model', 'mean_accuracy', 'std_accuracy']])\n",
    "        \n",
    "        return results_df, baseline_scores\n",
    "    else:\n",
    "        print(\"Ни одна модель не была успешно обучена\")\n",
    "        return pd.DataFrame(), baseline_scores\n",
    "\n",
    "def main():\n",
    "    print(\"=== ЗАПУСК ЭКСПЕРИМЕНТА ===\")\n",
    "    \n",
    "    # Установите необходимые библиотеки если их нет\n",
    "    try:\n",
    "        import chardet\n",
    "    except ImportError:\n",
    "        print(\"Установка chardet...\")\n",
    "        os.system(\"pip install chardet\")\n",
    "        import chardet\n",
    "    \n",
    "    try:\n",
    "        from charset_normalizer import from_bytes\n",
    "    except ImportError:\n",
    "        print(\"Установка charset-normalizer...\")\n",
    "        os.system(\"pip install charset-normalizer\")\n",
    "        from charset_normalizer import from_bytes\n",
    "    \n",
    "    # 1. Загрузка данных\n",
    "    train, test = safe_load_data()\n",
    "    if train.empty:\n",
    "        print(\"Ошибка: Не удалось загрузить тренировочные данные\")\n",
    "        return\n",
    "    \n",
    "    # 2. Предобработка\n",
    "    X_train, y_train, X_test = preprocess_data(train, test)\n",
    "    if X_train.empty or y_train.empty:\n",
    "        print(\"Ошибка: Проблемы с предобработкой данных\")\n",
    "        return\n",
    "    \n",
    "    # 3. Разделение на train/validation\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train, \n",
    "        y_train, \n",
    "        test_size=0.3, \n",
    "        random_state=SEED,\n",
    "        stratify=y_train\n",
    "    )\n",
    "    \n",
    "    print(f\"Данные загружены: Train {X_train.shape}, Val {X_val.shape}\")\n",
    "    \n",
    "    # 4. Обучение и оценка моделей\n",
    "    print(\"\\n=== ОБУЧЕНИЕ МОДЕЛЕЙ ===\")\n",
    "    preprocessor = create_preprocessor()\n",
    "    models = get_models()\n",
    "    results_df, _ = train_and_evaluate(X_train, y_train, preprocessor, models)\n",
    "    \n",
    "    if results_df.empty:\n",
    "        print(\"Не удалось обучить модели. Используем простую логистическую регрессию.\")\n",
    "        simple_model = Pipeline([\n",
    "            ('preprocessor', preprocessor),\n",
    "            ('model', LogisticRegression(max_iter=1000, random_state=SEED))\n",
    "        ])\n",
    "        simple_model.fit(X_train, y_train)\n",
    "        best_model = simple_model\n",
    "        best_model_name = \"LogisticRegression (fallback)\"\n",
    "    else:\n",
    "        best_model_info = results_df.iloc[0]\n",
    "        best_model = best_model_info['best_estimator']\n",
    "        best_model_name = best_model_info['model']\n",
    "        print(f\"\\nЛучшая модель: {best_model_name}\")\n",
    "        print(f\"Validation Accuracy: {best_model_info['mean_accuracy']:.4f}\")\n",
    "    \n",
    "    # 6. Оценка на валидационном наборе\n",
    "    val_predictions = best_model.predict(X_val)\n",
    "    val_accuracy = accuracy_score(y_val, val_predictions)\n",
    "    print(f\"\\nФинальная Validation Accuracy: {val_accuracy:.4f}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_val, val_predictions))\n",
    "    \n",
    "    # 7. Работа с тестовыми данными\n",
    "    if not X_test.empty:\n",
    "        print(\"\\n=== ОБРАБОТКА ТЕСТОВЫХ ДАННЫХ ===\")\n",
    "        test_predictions = best_model.predict(X_test)\n",
    "        \n",
    "        submission = pd.DataFrame({\n",
    "            'id': X_test.index,\n",
    "            'prediction': test_predictions,\n",
    "        })\n",
    "        \n",
    "        if not test.empty and 'successful' in test.columns:\n",
    "            public_accuracy = accuracy_score(test['successful'], test_predictions)\n",
    "            print(f\"Test Accuracy: {public_accuracy:.4f}\")\n",
    "    \n",
    "    # 8. Сохранение модели\n",
    "    try:\n",
    "        joblib.dump(best_model, 'best_model.pkl')\n",
    "        print(\"\\nМодель сохранена как 'best_model.pkl'\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при сохранении модели: {str(e)}\")\n",
    "\n",
    "    # Создание CSV файла с предсказаниями\n",
    "    try:\n",
    "        if not X_test.empty:\n",
    "            submission_df = pd.DataFrame({\n",
    "                'id': X_test.index,\n",
    "                'successful': test_predictions,\n",
    "            })\n",
    "        \n",
    "        \n",
    "        submission_df.to_csv('submission.csv', index=False, encoding='utf-8-sig', sep=';')\n",
    "        print(\"Предсказания сохранены как 'submission.csv'\")\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка при создании submission.csv: {str(e)}\")\n",
    "\n",
    "    print(\"\\n=== ЭКСПЕРИМЕНТ ЗАВЕРШЕН ===\")\n",
    "    print(f\"Лучшая модель: {best_model_name}\")\n",
    "    print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "# Запуск основной функции\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9053e57-db64-4559-b989-ae75d1cfd893",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888717ae-bb31-4b62-90db-2fd802725c8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
